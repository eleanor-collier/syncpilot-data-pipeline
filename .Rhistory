select(-word_timelabel) %>%
# Expand 'time' to include every 0.01 second between start and stop
group_by(ID, disclosure, text) %>%
complete(time = seq.int(
from=time[1],
to=time[2],
by=0.01
)) %>%
ungroup() %>%
select(-text) %>%
# Create is_speaking column and label all rows as TRUE
mutate(is_speaking = TRUE) %>%
# Delete duplicate time rows
group_by(ID, disclosure) %>%
distinct(time, .keep_all=T) %>%
ungroup() %>%
# Expland 'time' to include all time points when the participant wasn't talking, and
summary(is.na(transcripts_by_time$text))
#########################################################################################
# Make transcript data joinable to acoustic features data
transcripts_by_time <- transcripts_by_word[1:1000,] %>%
# Make a column called 'time' that includes start and stoptime for every word
pivot_longer(
cols = c(start_time, end_time),
names_to = "word_timelabel",
values_to = "time"
) %>%
select(-word_timelabel) %>%
# Expand 'time' to include every 0.01 second between start and stop
group_by(ID, disclosure, text) %>%
complete(time = seq.int(
from=time[1],
to=time[2],
by=0.01
)) %>%
ungroup() %>%
select(-text) %>%
# Create is_speaking column and label all rows as TRUE
mutate(is_speaking = TRUE) %>%
# Delete duplicate time rows
group_by(ID, disclosure) %>%
distinct(time, .keep_all=T) %>%
ungroup() #%>%
workspace
library(tidyverse)
library(roll)
library(DescTools)
get_data_here  <- "/Users/Eleanor2/Library/CloudStorage/GoogleDrive-airfire246@gmail.com/My Drive/UCR/UCR SNL/Research Projects/SyncDisclosures/Pilot/Analysis/Data/processed/moment_to_moment/"
# Set up workspace
library(tidyverse)
library(roll)
library(DescTools)
get_data_here  <- "/Users/Eleanor2/Library/CloudStorage/GoogleDrive-airfire246@gmail.com/My Drive/UCR/UCR SNL/Research Projects/SyncDisclosures/Pilot/Analysis/Data/processed/moment_to_moment/"
VADER_data     <- read_csv(paste0(get_data_here, 'transcripts_by_window_5s_vader.csv')) %>% distinct()
accoustic_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv"))
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv"))
View(vocal_data)
verbal_nonverbal_convergence <-
inner_join(VADER_data, vocal_data, by=c('ID', 'disclosure', 'time')) #%>%
View(verbal_nonverbal_convergence)
View(vocal_data)
View(vocal_data)
verbal_nonverbal_convergence <-
inner_join(VADER_data, vocal_data, by=c('ID', 'disclosure', 'time')) %>%
# Get correlation between verbal and nonverbal features
group_by(ID, disclosure) %>%
summarize(
arousal_conv = cor(vader_arousal, arousal_score, use="pairwise.complete.obs"),
) %>%
ungroup() #%>%
View(verbal_nonverbal_convergence)
library(ggpubr)
ggdensity(verbal_nonverbal_convergence$arousal_conv)
mean(verbal_nonverbal_convergence$arousal_conv)
median(verbal_nonverbal_convergence$arousal_conv)
verbal_nonverbal_convergence <-
inner_join(VADER_data, vocal_data, by=c('ID', 'disclosure', 'time')) %>%
# Get correlation between verbal and nonverbal features
group_by(ID, disclosure) %>%
summarize(
arousal_conv = cor(vader_arousal, arousal_score, use="pairwise.complete.obs"),
) %>%
ungroup() %>%
# Apply Fisher R to Z transformation
mutate_at(vars(matches("conv")), ~FisherZ(.)) %>%
# Get rid of Inf values (really only one recording that got cut short)
filter(valence_f2_conv!=Inf)
verbal_nonverbal_convergence <-
inner_join(VADER_data, vocal_data, by=c('ID', 'disclosure', 'time')) %>%
# Get correlation between verbal and nonverbal features
group_by(ID, disclosure) %>%
summarize(
arousal_conv = cor(vader_arousal, arousal_score, use="pairwise.complete.obs"),
) %>%
ungroup() %>%
# Apply Fisher R to Z transformation
mutate_at(vars(matches("conv")), ~FisherZ(.)) #%>%
verbal_nonverbal_convergence <-
inner_join(VADER_data, vocal_data, by=c('ID', 'disclosure', 'time')) %>%
# Get correlation between verbal and nonverbal features
group_by(ID, disclosure) %>%
summarize(
arousal_conv = cor(vader_arousal, arousal_score, use="pairwise.complete.obs"),
) %>%
ungroup() %>%
# Apply Fisher R to Z transformation
mutate_at(vars(matches("conv")), ~FisherZ(.)) #%>%
# Save data
save_data_here <- "/Volumes/GoogleDrive/My Drive/UCR/UCR SNL/Research Projects/SyncDisclosures/Pilot/Analysis/Data/processed/mean_by_disclosure/"
write_csv(verbal_nonverbal_convergence, paste0(save_data_here, "verbal_nonverbal_convergence.csv"))
# Save data
save_data_here <- "/Users/Eleanor2/Library/CloudStorage/GoogleDrive-airfire246@gmail.com/My Drive/UCR/UCR SNL/Research Projects/SyncDisclosures/Pilot/Analysis/Data/processed/mean_by_disclosure/"
write_csv(verbal_nonverbal_convergence, paste0(save_data_here, "verbal_nonverbal_convergence.csv"))
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv")) %>%
group_by(ID, disclosure) %>%
mutate_at(vars(arousal_score), ~roll_mean(., width = 5, min_obs = 1, complete_obs = T)) %>%
ungroup()
View(vocal_data)
verbal_nonverbal_convergence <-
inner_join(VADER_data, vocal_data, by=c('ID', 'disclosure', 'time')) %>%
# Get correlation between verbal and nonverbal features
group_by(ID, disclosure) %>%
summarize(
arousal_conv = cor(vader_arousal, arousal_score, use="pairwise.complete.obs"),
) %>%
ungroup() %>%
# Apply Fisher R to Z transformation
mutate_at(vars(matches("conv")), ~FisherZ(.)) #%>%
verbal_nonverbal_convergence <-
inner_join(VADER_data, vocal_data, by=c('ID', 'disclosure', 'time')) %>%
# Get correlation between verbal and nonverbal features
group_by(ID, disclosure) %>%
summarize(
arousal_conv = cor(vader_arousal, arousal_score, use="pairwise.complete.obs"),
) %>%
ungroup() %>%
# Apply Fisher R to Z transformation
mutate_at(vars(matches("conv")), ~FisherZ(.)) %>%
# Get rid of Inf values (really only one recording that got cut short)
filter(valence_f2_conv!=Inf)
verbal_nonverbal_convergence <-
inner_join(VADER_data, vocal_data, by=c('ID', 'disclosure', 'time')) %>%
# Get correlation between verbal and nonverbal features
group_by(ID, disclosure) %>%
summarize(
arousal_conv = cor(vader_arousal, arousal_score, use="pairwise.complete.obs"),
) %>%
ungroup() %>%
# Apply Fisher R to Z transformation
mutate_at(vars(matches("conv")), ~FisherZ(.)) %>%
# Get rid of Inf values (really only one recording that got cut short)
filter(valence_f2_conv!=Inf)
verbal_nonverbal_convergence <-
inner_join(VADER_data, vocal_data, by=c('ID', 'disclosure', 'time')) %>%
# Get correlation between verbal and nonverbal features
group_by(ID, disclosure) %>%
summarize(
arousal_conv = cor(vader_arousal, arousal_score, use="pairwise.complete.obs"),
) %>%
ungroup() %>%
# Apply Fisher R to Z transformation
mutate_at(vars(matches("conv")), ~FisherZ(.)) %>%
# Get rid of Inf values (really only one recording that got cut short)
filter(arousal_conv!=Inf)
# Save data
save_data_here <- "/Users/Eleanor2/Library/CloudStorage/GoogleDrive-airfire246@gmail.com/My Drive/UCR/UCR SNL/Research Projects/SyncDisclosures/Pilot/Analysis/Data/processed/mean_by_disclosure/"
write_csv(verbal_nonverbal_convergence, paste0(save_data_here, "verbal_nonverbal_convergence.csv"))
# Load data
accoustic_data <- read_csv(paste0(get_data_here, "accoustic_features_by_time.csv")) %>%
# Code for speech and silence
mutate(sound = case_when(pitch > 0 ~ 'speaking', pitch == 0 ~ 'silence')) #%>%
# Load data
acoustic_data <- read_csv(paste0(get_data_here, "acoustic_features_by_time.csv")) %>%
# Code for speech and silence
mutate(sound = case_when(pitch > 0 ~ 'speaking', pitch == 0 ~ 'silence')) #%>%
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv"))
View(acoustic_data)
vocal_data <- vocal_data %>%
left_join(acoustic_data %>% select(ID, disclosure, time, sound), by=c(c('ID', 'disclosure', 'time')))
View(vocal_data)
vocal_data <- vocal_data %>%
left_join(acoustic_data, by=c(c('ID', 'disclosure', 'time')))
# Load data
acoustic_data <- read_csv(paste0(get_data_here, "acoustic_features_by_time.csv")) %>%
mutate(ID = as.double(ID))
# Load data
acoustic_data <- read_csv(paste0(get_data_here, "acoustic_features_by_time.csv")) %>%
mutate(ID = as.double(ID)) %>%
# Code for speech and silence
mutate(sound = case_when(pitch > 0 ~ 'speaking', pitch == 0 ~ 'silence')) #%>%
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv"))
vocal_data <- vocal_data %>%
left_join(acoustic_data %>% select(ID, disclosure, time, sound), by=c(c('ID', 'disclosure', 'time')))
View(vocal_data)
verbal_nonverbal_convergence <-
inner_join(VADER_data, vocal_data, by=c('ID', 'disclosure', 'time')) %>%
# Filter for moments of speech only
filter(sound=="speaking") %>%
# Get correlation between verbal and nonverbal features
group_by(ID, disclosure) %>%
summarize(
arousal_conv = cor(vader_arousal, arousal_score, use="pairwise.complete.obs"),
) %>%
ungroup() %>%
# Apply Fisher R to Z transformation
mutate_at(vars(matches("conv")), ~FisherZ(.)) %>%
# Get rid of Inf values (really only one recording that got cut short)
filter(arousal_conv!=Inf)
# Save data
save_data_here <- "/Users/Eleanor2/Library/CloudStorage/GoogleDrive-airfire246@gmail.com/My Drive/UCR/UCR SNL/Research Projects/SyncDisclosures/Pilot/Analysis/Data/processed/mean_by_disclosure/"
write_csv(verbal_nonverbal_convergence, paste0(save_data_here, "verbal_nonverbal_convergence.csv"))
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv"))
vocal_data <- vocal_data %>%
left_join(acoustic_data %>% select(ID, disclosure, time, sound), by=c(c('ID', 'disclosure', 'time'))) %>%
# "Smudge" acoustic features across the same window used for VADER scores using a moving average
# First set values for moments of silence to NA
mutate_at(vars(pitch:f4), ~case_when(sound=='silence' ~ NA, sound=='speaking' ~ .)) %>%
group_by(ID, disclosure) %>%
mutate_at(vars(pitch:f4), ~roll_mean(., width = 5, min_obs = 1, complete_obs = T)) %>%
ungroup()
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv"))
vocal_data <- vocal_data %>%
left_join(acoustic_data %>% select(ID, disclosure, time, sound), by=c(c('ID', 'disclosure', 'time'))) %>%
# "Smudge" acoustic features across the same window used for VADER scores using a moving average
# First set values for moments of silence to NA
mutate_at(vars(arousal_score), ~case_when(sound=='silence' ~ NA, sound=='speaking' ~ .)) %>%
group_by(ID, disclosure) %>%
mutate_at(vars(arousal_score), ~roll_mean(., width = 5, min_obs = 1, complete_obs = T)) %>%
ungroup()
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv"))
vocal_data <- vocal_data %>%
left_join(acoustic_data %>% select(ID, disclosure, time, sound), by=c(c('ID', 'disclosure', 'time'))) %>%
# "Smudge" acoustic features across the same window used for VADER scores using a moving average
# First set values for moments of silence to NA
mutate_at(vars(arousal_score), ~case_when(sound=='silence' ~ NA, sound=='speaking' ~ .)) #%>%
View(vocal_data)
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv")) %>%
left_join(acoustic_data %>% select(ID, disclosure, time, sound), by=c(c('ID', 'disclosure', 'time')))
View(vocal_data)
vocal_data <- vocal_data %>%
# "Smudge" acoustic features across the same window used for VADER scores using a moving average
# First set values for moments of silence to NA
mutate_at(vars(arousal_score), ~case_when(sound=='silence' ~ NA, sound=='speaking' ~ .)) #%>%
View(vocal_data)
vocal_data <- vocal_data %>%
# "Smudge" acoustic features across the same window used for VADER scores using a moving average
# First set values for moments of silence to NA
#mutate_at(vars(arousal_score), ~case_when(sound=='silence' ~ NA, sound=='speaking' ~ .)) #%>%
group_by(ID, disclosure) %>%
mutate_at(vars(arousal_score), ~roll_mean(., width = 5, min_obs = 1, complete_obs = T)) %>%
ungroup()
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv")) %>%
left_join(acoustic_data %>% select(ID, disclosure, time, sound), by=c(c('ID', 'disclosure', 'time')))
vocal_data <- vocal_data %>%
# "Smudge" acoustic features across the same window used for VADER scores using a moving average
# First set values for moments of silence to NA
mutate_at(vars(arousal_score), ~case_when(sound=='silence' ~ NA)) #%>%
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv")) %>%
left_join(acoustic_data %>% select(ID, disclosure, time, sound), by=c(c('ID', 'disclosure', 'time')))
vocal_data <- vocal_data %>%
# "Smudge" acoustic features across the same window used for VADER scores using a moving average
# First set values for moments of silence to NA
mutate_at(vars(arousal_score), ~case_when(sound=='silence' ~ NA)) #%>%
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv")) %>%
left_join(acoustic_data %>% select(ID, disclosure, time, sound), by=c(c('ID', 'disclosure', 'time')))
View(verbal_nonverbal_convergence)
View(vocal_data)
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv")) %>%
left_join(acoustic_data %>% select(ID, disclosure, time, sound), by=c(c('ID', 'disclosure', 'time')))
vocal_data <- vocal_data %>%
# "Smudge" acoustic features across the same window used for VADER scores using a moving average
# First set values for moments of silence to NA
mutate_at(vars(arousal_score), ~case_when(sound=='silence' ~ NA, TRUE ~ .)) #%>%
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv")) %>%
left_join(acoustic_data %>% select(ID, disclosure, time, sound), by=c(c('ID', 'disclosure', 'time')))
vocal_data <- vocal_data %>%
# "Smudge" acoustic features across the same window used for VADER scores using a moving average
# First set values for moments of silence to NA
mutate_at(vars(arousal_score), ~case_when(sound=='speaking' ~ .)) #%>%
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv")) %>%
left_join(acoustic_data %>% select(ID, disclosure, time, sound), by=c(c('ID', 'disclosure', 'time')))
vocal_data <- vocal_data %>%
# "Smudge" acoustic features across the same window used for VADER scores using a moving average
# First set values for moments of silence to NA
mutate_at(vars(arousal_score), ~case_when(sound=='speaking' ~ ., sound=='silence' ~ NA)) #%>%
vocal_data <- vocal_data %>%
# "Smudge" acoustic features across the same window used for VADER scores using a moving average
# First set values for moments of silence to NA
mutate_at(vars(arousal_score), ~case_when(
sound=='silence' ~ NA,
sound=='speaking' ~ .
)) #%>%
vocal_data <- vocal_data %>%
# "Smudge" acoustic features across the same window used for VADER scores using a moving average
# First set values for moments of silence to NA
mutate_at(vars(arousal_score), ~case_when(
sound=='silence' ~ NA,
sound=='speaking' ~ .,
TRUE ~ .
)) #%>%
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv")) %>%
left_join(acoustic_data %>% select(ID, disclosure, time, sound), by=c(c('ID', 'disclosure', 'time')))
vocal_data <- vocal_data %>%
# "Smudge" acoustic features across the same window used for VADER scores using a moving average
# First set values for moments of silence to NA
mutate_at(vars(arousal_score), ~case_when(
sound=='silence' ~ NA,
sound=='speaking' ~ .,
TRUE ~ .
)) #%>%
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv")) %>%
left_join(acoustic_data %>% select(ID, disclosure, time, sound), by=c(c('ID', 'disclosure', 'time')))
vocal_data <- vocal_data %>%
# "Smudge" acoustic features across the same window used for VADER scores using a moving average
# First set values for moments of silence to NA
mutate_at(vars(arousal_score), ~case_when(
sound=='silence' ~ NA_real_,
sound=='speaking' ~ .
)) #%>%
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv")) %>%
left_join(acoustic_data %>% select(ID, disclosure, time, sound), by=c(c('ID', 'disclosure', 'time')))
vocal_data <- vocal_data %>%
# "Smudge" acoustic features across the same window used for VADER scores using a moving average
# First set values for moments of silence to NA
mutate_at(vars(arousal_score), ~case_when(
sound=='silence' ~ NA_real_,
sound=='speaking' ~ .
)) %>%
group_by(ID, disclosure) %>%
mutate_at(vars(arousal_score), ~roll_mean(., width = 5, min_obs = 1, complete_obs = T)) %>%
ungroup()
View(VADER_data)
View(vocal_data)
verbal_nonverbal_convergence <-
inner_join(VADER_data, vocal_data, by=c('ID', 'disclosure', 'time')) %>%
# Filter for moments of speech only
filter(sound=="speaking") %>%
# Get correlation between verbal and nonverbal features
group_by(ID, disclosure) %>%
summarize(
arousal_conv = cor(vader_arousal, arousal_score, use="pairwise.complete.obs"),
) %>%
ungroup() %>%
# Apply Fisher R to Z transformation
mutate_at(vars(matches("conv")), ~FisherZ(.)) %>%
# Get rid of Inf values (really only one recording that got cut short)
filter(arousal_conv!=Inf)
# Save data
save_data_here <- "/Users/Eleanor2/Library/CloudStorage/GoogleDrive-airfire246@gmail.com/My Drive/UCR/UCR SNL/Research Projects/SyncDisclosures/Pilot/Analysis/Data/processed/mean_by_disclosure/"
write_csv(verbal_nonverbal_convergence, paste0(save_data_here, "verbal_nonverbal_convergence.csv"))
View(verbal_nonverbal_convergence)
# Set up workspace
library(tidyverse)
library(roll)
library(DescTools)
get_data_here  <- "/Users/Eleanor2/Library/CloudStorage/GoogleDrive-airfire246@gmail.com/My Drive/UCR/UCR SNL/Research Projects/SyncDisclosures/Pilot/Analysis/Data/processed/moment_to_moment/"
# Load data
acoustic_data <- read_csv(paste0(get_data_here, "acoustic_features_by_time.csv")) %>%
mutate(ID = as.double(ID)) %>%
# Code for speech and silence
mutate(sound = case_when(pitch > 0 ~ 'speaking', pitch == 0 ~ 'silence')) #%>%
View(acoustic_data)
View(acoustic_data)
nrow(acoustic_data %>% filter(pitch <0))
nrow(acoustic_data %>% filter(intensity <0))
nrow(acoustic_data %>% filter(pitch == 0))/nrow(acoustic_data %>% filter(pitch != 0))
nrow(acoustic_data %>% filter(pitch == 0))
nrow(acoustic_data %>% filter(pitch != 0))
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv")) %>%
left_join(acoustic_data %>% select(ID, disclosure, time, sound), by=c(c('ID', 'disclosure', 'time')))
View(vocal_data)
VADER_data     <- read_csv(paste0(get_data_here, 'transcripts_by_window_5s_vader.csv')) %>% distinct()
View(VADER_data)
View(VADER_data)
vocal_data <- vocal_data %>%
# First set values for moments of silence to NA
mutate_at(vars(arousal_score), ~case_when(
sound=='silence' ~ NA_real_,
sound=='speaking' ~ .
)) #%>%
View(vocal_data)
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv")) %>%
left_join(acoustic_data %>% select(ID, disclosure, time, sound), by=c(c('ID', 'disclosure', 'time')))
# Set up workspace
library(tidyverse)
library(vroom)
# Load data
get_data_here  <- "/Volumes/GoogleDrive/My Drive/UCR/UCR SNL/Research Projects/SyncDisclosures/Pilot/Analysis/data/processed/moment_to_moment/"
save_data_here <- "/Volumes/GoogleDrive/My Drive/UCR/UCR SNL/Research Projects/SyncDisclosures/Pilot/Analysis/processing_pipeline/get_prosody/data_for_ML/"
transcripts_by_word <- vroom(paste0(get_data_here, 'transcripts_by_word.csv'))
acoustic_features_by_time <- vroom(paste0(get_data_here, 'acoustic_features_by_time.csv'))
#########################################################################################
## Make transcript data joinable to acoustic features data
transcripts_by_time <- transcripts_by_word[1:1000,] %>%
# Make a column called 'time' that includes start and stoptime for every word
pivot_longer(
cols = c(start_time, end_time),
names_to = "word_timelabel",
values_to = "time"
) %>%
select(-word_timelabel) %>%
# Expand 'time' to include every 0.01 second between start and stop
group_by(ID, disclosure, text) %>%
complete(time = seq.int(
from=time[1],
to=time[2],
by=0.01
)) %>%
ungroup() %>%
select(-text) %>%
# Create is_speaking column and label all rows as TRUE
mutate(is_speaking = TRUE) %>%
# Delete duplicate time rows
group_by(ID, disclosure) %>%
distinct(time, .keep_all=T) %>%
ungroup()
# Set up workspace
library(tidyverse)
library(vroom)
# Load data
get_data_here  <- "/Users/Eleanor2/Library/CloudStorage/GoogleDrive-airfire246@gmail.com/My Drive/UCR/UCR SNL/Research Projects/SyncDisclosures/Pilot/Analysis/Data/processed/moment_to_moment/"
save_data_here <- "/Users/Eleanor2/Library/CloudStorage/GoogleDrive-airfire246@gmail.com/My Drive/UCR/UCR SNL/Research Projects/SyncDisclosures/Pilot/Analysis/processing_pipeline/get_prosody/data_for_ML/"
transcripts_by_word <- vroom(paste0(get_data_here, 'transcripts_by_word.csv'))
acoustic_features_by_time <- vroom(paste0(get_data_here, 'acoustic_features_by_time.csv'))
#########################################################################################
## Make transcript data joinable to acoustic features data
transcripts_by_time <- transcripts_by_word[1:1000,] %>%
# Make a column called 'time' that includes start and stoptime for every word
pivot_longer(
cols = c(start_time, end_time),
names_to = "word_timelabel",
values_to = "time"
) %>%
select(-word_timelabel) %>%
# Expand 'time' to include every 0.01 second between start and stop
group_by(ID, disclosure, text) %>%
complete(time = seq.int(
from=time[1],
to=time[2],
by=0.01
)) %>%
ungroup() %>%
select(-text) %>%
# Create is_speaking column and label all rows as TRUE
mutate(is_speaking = TRUE) %>%
# Delete duplicate time rows
group_by(ID, disclosure) %>%
distinct(time, .keep_all=T) %>%
ungroup()
View(transcripts_by_time)
View(transcripts_by_word)
# Set up workspace
library(tidyverse)
library(roll)
library(DescTools)
get_data_here  <- "/Users/Eleanor2/Library/CloudStorage/GoogleDrive-airfire246@gmail.com/My Drive/UCR/UCR SNL/Research Projects/SyncDisclosures/Pilot/Analysis/Data/processed/moment_to_moment/"
# NEXT: Use transcripts by word to create a more accurate measure of when the participant is speaking
# Need to fix code first
# Load data
acoustic_data <- read_csv(paste0(get_data_here, "acoustic_features_by_time.csv")) %>%
mutate(ID = as.double(ID)) %>%
# Code for speech and silence
mutate(sound = case_when(pitch > 0 ~ 'speaking', pitch == 0 ~ 'silence')) #%>%
# "Smudge" acoustic features across the same window used for VADER scores using a moving average
# First set values for moments of silence to NA
# mutate_at(vars(pitch:f4), ~case_when(sound=='silence' ~ NA, sound=='speaking' ~ .)) %>%
# group_by(ID, disclosure) %>%
# mutate_at(vars(pitch:f4), ~roll_mean(., width = 15, min_obs = 1, complete_obs = T)) %>%
# ungroup()
vocal_data <- read_csv(paste0(get_data_here, "vocal_arousal_by_time.csv")) %>%
left_join(acoustic_data %>% select(ID, disclosure, time, sound), by=c(c('ID', 'disclosure', 'time')))
vocal_data <- vocal_data %>%
# First set values for moments of silence to NA
mutate_at(vars(arousal_score), ~case_when(
sound=='silence' ~ NA_real_,
sound=='speaking' ~ .
)) #%>%
# # "Smudge" acoustic features across the same window used for VADER scores using a moving average
# group_by(ID, disclosure) %>%
# mutate_at(vars(arousal_score), ~roll_mean(., width = 5, min_obs = 1, complete_obs = T)) %>%
# ungroup()
VADER_data     <- read_csv(paste0(get_data_here, 'transcripts_by_window_5s_vader.csv')) %>% distinct()
library(ggpubr)
verbal_nonverbal_convergence <-
inner_join(VADER_data, vocal_data, by=c('ID', 'disclosure', 'time')) %>%
# Filter for moments of speech only
filter(sound=="speaking") %>%
# Get correlation between verbal and nonverbal features
group_by(ID, disclosure) %>%
summarize(
arousal_conv = cor(vader_arousal, arousal_score, use="pairwise.complete.obs")
) %>%
ungroup() #%>%
ggdensity(verbal_nonverbal_convergence$arousal_conv)
verbal_nonverbal_convergence <-
inner_join(VADER_data, vocal_data, by=c('ID', 'disclosure', 'time')) %>%
# Filter for moments of speech only
filter(sound=="speaking") %>%
# Get correlation between verbal and nonverbal features
group_by(ID, disclosure) %>%
summarize(
arousal_conv = cor(vader_arousal, arousal_score, use="pairwise.complete.obs")
) %>%
ungroup() %>%
# Apply Fisher R to Z transformation
mutate_at(vars(matches("conv")), ~FisherZ(.)) %>%
# Get rid of Inf values (really only one recording that got cut short)
filter(arousal_conv!=Inf)
ggdensity(verbal_nonverbal_convergence$arousal_conv)
# Save data
save_data_here <- "/Users/Eleanor2/Library/CloudStorage/GoogleDrive-airfire246@gmail.com/My Drive/UCR/UCR SNL/Research Projects/SyncDisclosures/Pilot/Analysis/Data/processed/mean_by_disclosure/"
write_csv(verbal_nonverbal_convergence, paste0(save_data_here, "verbal_nonverbal_convergence.csv"))
